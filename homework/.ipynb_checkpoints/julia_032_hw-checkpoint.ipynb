{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia 深度學習：類神經網路模型簡介\n",
    "\n",
    "## 作業 032：訓練 MLP 學習門牌號碼資料集\n",
    "\n",
    "訓練一個 MLP 模型來學習門牌號碼資料集。\n",
    "\n",
    "注意：MLP 模型的能力有限，可能會導致訓練起來效果不佳。\n",
    "\n",
    "注意：近期 Flux 正在持續更新，請確保您的 Julia 在 v1.3 版以上，以及 Flux 在 v0.10.4 以上或是最新版。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1260\n",
      "┌ Warning: Module CuArrays with build ID 317652047236201 is missing from the cache.\n",
      "│ This may mean CuArrays [3a865a2d-5b23-5a0f-bc46-62713ec82fae] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:1016\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing Flux [587475ba-b771-5e3f-ad9e-33799f191a9c].\n",
      "└ @ Base loading.jl:1033\n",
      "┌ Info: Precompiling CodecZlib [944b1d66-785c-5afd-91f1-9de20f533193]\n",
      "└ @ Base loading.jl:1260\n",
      "┌ Info: Precompiling MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy\n",
    "using MLDatasets\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "呼叫 SVHN2 資料集的過程中，會先去檢查以前是否有下載過，如果是第一次下載，過程中會詢問是否下載資料集，請回答 `y`。整個資料集的大小約為 1.6 GB，下載時間可能會稍久，請耐心等候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.14901961 0.15294118 … 0.19607843 0.1882353; 0.15294118 0.15294118 … 0.2 0.1882353; … ; 0.16470589 0.16862746 … 0.1764706 0.17254902; 0.15294118 0.15294118 … 0.16470589 0.16470589]\n",
       "\n",
       "Float32[0.40392157 0.40784314 … 0.45882353 0.4509804; 0.40784314 0.40784314 … 0.4627451 0.4509804; … ; 0.40392157 0.39607844 … 0.45490196 0.4509804; 0.38039216 0.38039216 … 0.44313726 0.44313726]\n",
       "\n",
       "Float32[0.23529412 0.23921569 … 0.29803923 0.2901961; 0.23921569 0.23921569 … 0.3019608 0.2901961; … ; 0.24313726 0.24705882 … 0.28235295 0.2784314; 0.22352941 0.22352941 … 0.27058825 0.2784314]\n",
       "\n",
       "Float32[0.5058824 0.5254902 … 0.5411765 0.5137255; 0.49803922 0.52156866 … 0.50980395 0.47843137; … ; 0.48235294 0.49411765 … 0.39607844 0.43529412; 0.48235294 0.49019608 … 0.4392157 0.48235294]\n",
       "\n",
       "Float32[0.5568628 0.5882353 … 0.59607846 0.5686275; 0.56078434 0.58431375 … 0.5647059 0.53333336; … ; 0.5254902 0.5372549 … 0.41960785 0.4627451; 0.5294118 0.5372549 … 0.4627451 0.50980395]\n",
       "\n",
       "Float32[0.6 0.627451 … 0.64705884 0.61960787; 0.59607846 0.61960787 … 0.6156863 0.58431375; … ; 0.6117647 0.6156863 … 0.5254902 0.5647059; 0.6156863 0.61960787 … 0.5647059 0.6117647]\n",
       "\n",
       "Float32[0.5882353 0.5882353 … 0.5764706 0.62352943; 0.5882353 0.5921569 … 0.5764706 0.62352943; … ; 0.5882353 0.6 … 0.54509807 0.59607846; 0.5764706 0.5882353 … 0.5411765 0.59607846]\n",
       "\n",
       "Float32[0.627451 0.627451 … 0.64705884 0.69411767; 0.6392157 0.6392157 … 0.6431373 0.69411767; … ; 0.67058825 0.67058825 … 0.60784316 0.65882355; 0.6627451 0.6627451 … 0.60784316 0.65882355]\n",
       "\n",
       "Float32[0.6627451 0.6627451 … 0.7019608 0.7411765; 0.6666667 0.6627451 … 0.7019608 0.74509805; … ; 0.70980394 0.7058824 … 0.6666667 0.7137255; 0.7058824 0.7019608 … 0.67058825 0.7176471]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.4509804 0.47843137 … 0.45882353 0.5176471; 0.45490196 0.48235294 … 0.45882353 0.52156866; … ; 0.44705883 0.4627451 … 0.56078434 0.56078434; 0.4509804 0.46666667 … 0.5647059 0.5647059]\n",
       "\n",
       "Float32[0.5176471 0.54509807 … 0.47843137 0.5411765; 0.52156866 0.54901963 … 0.47843137 0.54901963; … ; 0.53333336 0.54509807 … 0.6117647 0.6117647; 0.53333336 0.54509807 … 0.6156863 0.6156863]\n",
       "\n",
       "Float32[0.5568628 0.5803922 … 0.5372549 0.59607846; 0.56078434 0.58431375 … 0.5372549 0.59607846; … ; 0.5568628 0.5686275 … 0.6431373 0.64705884; 0.56078434 0.57254905 … 0.64705884 0.64705884]\n",
       "\n",
       "Float32[0.3764706 0.3764706 … 0.38431373 0.38039216; 0.38039216 0.38039216 … 0.3882353 0.3882353; … ; 0.34117648 0.34117648 … 0.4627451 0.43529412; 0.34509805 0.34509805 … 0.43137255 0.40784314]\n",
       "\n",
       "Float32[0.25490198 0.25490198 … 0.2627451 0.25882354; 0.25490198 0.25490198 … 0.27450982 0.27058825; … ; 0.24313726 0.24705882 … 0.3882353 0.36078432; 0.24705882 0.2509804 … 0.35686275 0.33333334]\n",
       "\n",
       "Float32[0.18431373 0.1882353 … 0.18039216 0.1764706; 0.19215687 0.19607843 … 0.1882353 0.1882353; … ; 0.21568628 0.21176471 … 0.3254902 0.2901961; 0.21960784 0.21568628 … 0.29411766 0.26666668]\n",
       "\n",
       "Float32[0.39607844 0.42745098 … 0.40784314 0.37254903; 0.39215687 0.41960785 … 0.4117647 0.3764706; … ; 0.37254903 0.3647059 … 0.4 0.4; 0.3764706 0.3647059 … 0.4 0.4]\n",
       "\n",
       "Float32[0.29411766 0.32941177 … 0.3254902 0.28627452; 0.28627452 0.3137255 … 0.32941177 0.2901961; … ; 0.24705882 0.23921569 … 0.2784314 0.2784314; 0.2509804 0.23921569 … 0.2784314 0.2784314]\n",
       "\n",
       "Float32[0.23529412 0.27058825 … 0.2784314 0.24313726; 0.23529412 0.2627451 … 0.28627452 0.24705882; … ; 0.20392157 0.19607843 … 0.19607843 0.19607843; 0.2 0.19215687 … 0.19607843 0.19607843], [5, 2, 1, 10, 6, 1, 9, 1, 1, 8  …  1, 7, 1, 3, 6, 2, 2, 7, 6, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = SVHN2.traindata(Float32;dir = \"D:\\\\julia\\\\data\\\\SVHN2\")\n",
    "test_X,  test_y  = SVHN2.testdata(Float32;dir = \"D:\\\\julia\\\\data\\\\SVHN2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32,4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 73257)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Int64,1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       "  1\n",
       "  9\n",
       "  2\n",
       "  3\n",
       "  5\n",
       "  8\n",
       "  7\n",
       "  4\n",
       "  6\n",
       " 10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072×26032 Array{Float32,2}:\n",
       " 0.14902   0.505882  0.588235  0.509804  …  0.45098   0.376471  0.396078\n",
       " 0.152941  0.498039  0.588235  0.505882     0.454902  0.380392  0.392157\n",
       " 0.152941  0.490196  0.596078  0.498039     0.458824  0.380392  0.388235\n",
       " 0.160784  0.490196  0.603922  0.486275     0.454902  0.376471  0.384314\n",
       " 0.168627  0.498039  0.611765  0.501961     0.458824  0.372549  0.376471\n",
       " 0.172549  0.498039  0.603922  0.513726  …  0.466667  0.364706  0.364706\n",
       " 0.176471  0.494118  0.584314  0.521569     0.470588  0.360784  0.34902\n",
       " 0.184314  0.482353  0.556863  0.521569     0.470588  0.352941  0.345098\n",
       " 0.184314  0.482353  0.545098  0.52549      0.462745  0.352941  0.337255\n",
       " 0.184314  0.486275  0.556863  0.529412     0.458824  0.356863  0.333333\n",
       " 0.184314  0.494118  0.576471  0.529412  …  0.458824  0.360784  0.329412\n",
       " 0.184314  0.490196  0.607843  0.517647     0.458824  0.360784  0.321569\n",
       " 0.184314  0.486275  0.623529  0.501961     0.458824  0.364706  0.313726\n",
       " ⋮                                       ⋱            ⋮         \n",
       " 0.309804  0.584314  0.752941  0.568627  …  0.564706  0.219608  0.2\n",
       " 0.309804  0.588235  0.745098  0.560784     0.6       0.207843  0.196078\n",
       " 0.309804  0.607843  0.741176  0.54902      0.639216  0.227451  0.184314\n",
       " 0.301961  0.603922  0.737255  0.533333     0.662745  0.243137  0.176471\n",
       " 0.294118  0.588235  0.729412  0.52549      0.662745  0.270588  0.176471\n",
       " 0.294118  0.580392  0.721569  0.533333  …  0.666667  0.301961  0.180392\n",
       " 0.290196  0.588235  0.717647  0.541176     0.666667  0.321569  0.184314\n",
       " 0.282353  0.580392  0.717647  0.54902      0.65098   0.333333  0.184314\n",
       " 0.282353  0.541176  0.713726  0.560784     0.643137  0.341176  0.184314\n",
       " 0.278431  0.529412  0.709804  0.588235     0.643137  0.321569  0.192157\n",
       " 0.278431  0.564706  0.713726  0.623529  …  0.647059  0.290196  0.196078\n",
       " 0.278431  0.611765  0.717647  0.658824     0.647059  0.266667  0.196078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform (w, h, c, b)-shaped input into (w × h × c, b)-shaped output by\n",
    "#   linearizing all values for each element in the batch.\n",
    "train_X = Flux.flatten(train_X) # to minibatch\n",
    "test_X = Flux.flatten(test_X) # to minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×26032 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  0  1  0  0  1  0  1  1  0  0  0  0  …  1  0  1  0  1  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  1  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  1  0  0     0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  1     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  1  0  …  0  0  0  0  0  0  1  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  1  0  1\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  1  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  1  0  0  0  0  0  0  0  0  0     0  1  0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = onehotbatch(train_y, 1:10) # e.g. convert [1 2 2 1] (id of category) into [1 0 0 1; 0 1 1 0]\n",
    "test_y = onehotbatch(test_y, 1:10) # 1:10 because unique(train_y) is 1:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader((Float32[0.14901961 0.5058824 … 0.3764706 0.39607844; 0.15294118 0.49803922 … 0.38039216 0.39215687; … ; 0.2784314 0.5647059 … 0.2901961 0.19607843; 0.2784314 0.6117647 … 0.26666668 0.19607843], Bool[0 0 … 0 0; 0 1 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 1, 26032, true, 26032, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  26023, 26024, 26025, 26026, 26027, 26028, 26029, 26030, 26031, 26032], false)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = DataLoader(train_X,train_y, batchsize=1024, shuffle=true)\n",
    "test = DataLoader(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(3072, 256, relu), Dense(256, 128, relu), Dense(128, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1end = 256;\n",
    "layer2end = 128;\n",
    "\n",
    "model = Chain(\n",
    "    Dense(size(train_X,1),layer1end,relu),\n",
    "    Dense(layer1end,layer2end,relu),\n",
    "    Dense(layer2end,size(train_y,1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test` (type: `DataLoader`) is a generator that outputs (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_loss()\n",
    "    L = 0f0 # Use Float32 to save GPU memory\n",
    "    for (x, y) in test\n",
    "        L += loss(x, y)\n",
    "    end\n",
    "    L/length(test)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb() = @show(test_loss())  # for displaying current progress only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 17.654922f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 4.05785f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.1313214f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.2584875f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.2889419f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.2409694f0\n",
      "test_loss() = 3.0780807f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.0603104f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.5132546f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 4.170439f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 11\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.36852f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 12\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.8231251f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 13\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.2760942f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 14\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.1102757f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 15\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 4.1055994f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 16\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 4.8159614f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 17\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.7527559f0\n",
      "test_loss() = 5.8747187f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 18\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 19\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 3.7824585f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 20\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 5.0791707f0\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "timeout_in_seconds = 10\n",
    "ps = Flux.params(model)\n",
    "@epochs epochs Flux.train!(loss, ps, train, ADAM(0.005), cb=throttle(evalcb, timeout_in_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5751382913337431"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "accuracy(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
