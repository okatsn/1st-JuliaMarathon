{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia 深度學習：類神經網路模型簡介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本範例需要使用到的套件有 Flux，請在執行以下範例前先安裝。\n",
    "\n",
    "```\n",
    "] add Flux\n",
    "```\n",
    "\n",
    "注意：近期 Flux 正在持續更新，請確保您的 Julia 在 v1.3 版以上，以及 Flux 在 v0.10.4 以上或是最新版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flux 是 Julia 中知名的深度學習框架，它是完全以 Julia 實作，運算效率上是依賴 Julia 語⾔言本⾝身。套件本⾝身使⽤用 Julia 語⾔言的陣列列，並與語法相容。\n",
    "- Flux 的⾃自動微分功能是由 Zygote 提供\n",
    "- Flux 有 Keras 般以層為基礎的網路路搭建方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"Flux\")\n",
    "# Pkg.add(\"MLDatasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if error occurred during precompling, close jupyter and re-open as administrator\n",
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Data: DataLoader # bring just DataLoader into scope from Flux.Data\n",
    "using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy\n",
    "using MLDatasets\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料\n",
    "- `train_x`: input in training phase\n",
    "- `test_x`: input information for making prediction\n",
    "- `train_y`: answer (id of category) for in training phase\n",
    "- `test_y`: answer (id of category) for in predicting phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我們使用 MLDatasets 套件中的 MNIST 資料集。\n",
    "train_X, train_y0 = MNIST.traindata(Float32)\n",
    "test_X, test_y = MNIST.testdata(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data X: type = Array{Float32,3}, size = (28, 28, 60000)\n",
      "Training data y: type = Array{Int64,1}, size = (60000,)\n",
      "Testing data X: type = Array{Float32,3}, size = (28, 28, 10000)\n",
      "Testing data y: type = Array{Int64,1}, size = (10000,)\n"
     ]
    }
   ],
   "source": [
    "println(\"Training data X: type = $(typeof(train_X)), size = $(size(train_X))\")\n",
    "println(\"Training data y: type = $(typeof(train_y0)), size = $(size(train_y0))\")\n",
    "println(\"Testing data X: type = $(typeof(test_X)), size = $(size(test_X))\")\n",
    "println(\"Testing data y: type = $(typeof(test_y)), size = $(size(test_y))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 這邊需要先將資料切成 minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatten: convert each input data into 1 dimension\n",
    "  - e.g. the following train_X has a size of $784\\times 60000$, $784 = 28 \\times 28$ is the flattened 1d-array, $60000$ is total number of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened training data X: type = Array{Float32,2}, size = (784, 60000)\n",
      "Flattened testing data X: type = Array{Float32,2}, size = (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Transform (w, h, c, b)-shaped input into (w × h × c, b)-shaped output by\n",
    "#   linearizing all values for each element in the batch.\n",
    "train_X = Flux.flatten(train_X)\n",
    "test_X = Flux.flatten(test_X)\n",
    "println(\"Flattened training data X: type = $(typeof(train_X)), size = $(size(train_X))\")\n",
    "println(\"Flattened testing data X: type = $(typeof(test_X)), size = $(size(test_X))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onehot:\n",
    "e.g. convert [1 2 2 1] (id of category) into two dimensional [1 0 0 1; 0 1 1 0] array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       " 5\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 9\n",
       " 2\n",
       " 3\n",
       " 6\n",
       " 7\n",
       " 8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total possible category\n",
    "unique(train_y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  0  0  1  0  0  0  0  0  0  1  0  0  …  0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  1  0  0  1  0  0  0  0  0  0  0     0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  1  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  1  0  1  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  1  0  0\n",
       " 0  0  0  0  0  0  0  0  1  0  0  0  0  …  1  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0     0  1  0  0  0  0  0  0  0  0  0  1\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  0  1  0  0  1     0  0  0  0  1  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = onehotbatch(train_y0, 0:9) # 0:9 because unique(train_y) is 0:9\n",
    "test_y = onehotbatch(test_y, 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y0[1] # category 5 (category from 0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Flux.OneHotVector:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:,1] # converted to a vector identifying the category by 1 or 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the data into smaller batches of each batchsize (i.e. minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader`: An object that iterates over mini-batches of data\n",
    "- batchsize\n",
    "    - Considering train_X has a size of (256,n); train_y, (10,n); n is 10000 the total number of data (each column is a set of input for 1st level):\n",
    "        - DataLoader(train_X, train_y, batchsize=128) split the data into batches. For train_X, each batch has a size of (256,128); for train_y, (10,128)\n",
    "    - This is required to render the process tractable for GPU.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader((Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 1024, 10000, true, 10000, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], false)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 1024\n",
    "train = DataLoader(train_X, train_y, batchsize=batchsize, shuffle=true)\n",
    "test = DataLoader(test_X, test_y, batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFN (feedforward neural network) 模型\n",
    "- `Dense(dim_in, dim_out, activ_fn, sigm)`\n",
    "    - `dim_in`: dimensions of the input variable\n",
    "    - `dim_out`: dimensions of the output variable\n",
    "    - `activ_fn`: activation function. `identity()` in default\n",
    "    - `sigm`: sigmoid function\n",
    "    - a layer is a function\n",
    "- `softmax`: Softmax function，又被稱為『歸一化指數函數』，基本上是將一組向量（就好比說我們 Machine Learning 最後輸出的預測結果有多個分類，每個分類有著一個分數）映射為每個向量當中的元素都位於 (0, 1) 之間，其實就是代表著每個分類的機率分佈。當然，既然是機率分佈，那麼這個向量的總和應該要為 1。[Source](https://clay-atlas.com/blog/2019/10/20/machine-learning-chinese-softmax-function/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### link layers with `Flux.Chain` \n",
    "- Chain 也可以用在一般的函數或是其他函式。\n",
    "\n",
    "#### Create a traditional `Dense` layer with parameters W and b.\n",
    "- y = σ.(W * x .+ b)\n",
    "- The input x must be a vector of length in, or a batch of vectors represented as an in × N matrix. The out y will be a vector or batch of length out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chainfunc = Chain(\n",
    "x -> x+2,\n",
    "x -> x*3 \n",
    ")\n",
    "chainfunc(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 256, relu), Dense(256, 128, relu), Dense(128, 10), softmax)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1in = size(train_X,1);\n",
    "layer1out = 256;\n",
    "layer2out = 128;\n",
    "finalout = size(train_y,1);\n",
    "\n",
    "model = Chain(\n",
    "  Dense(layer1in, layer1out, relu), # First layer, where the input has to be an array of 784 by 1.\n",
    "  Dense(layer1out, layer2out, relu), # a layer is a function\n",
    "  Dense(layer2out, 10), # Final layer of 10 categories (total 10 possible answers).\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 256, relu), Dense(256, 128, relu), Dense(128, 10), logsoftmax)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "  Dense(784, 256, relu), # First layer, where the input has to be an array of 784 by 1.\n",
    "  Dense(256, 128, relu), # a layer is a function\n",
    "  Dense(128, 10), # Final layer of 10 categories (total 10 possible answers).\n",
    "  logsoftmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失函數\n",
    "- minimize residuals\n",
    "    - $\\text{residual} = y - \\hat{y}$, in which $y$表示實際類別，$\\hat{y}$表示預測類別\n",
    "- popular loss function\n",
    "    - for Regression\n",
    "        - Mean square error，MSE\n",
    "        - Mean absolute error，MAE\n",
    "        - MAE對outlier比較有用，但因為微分不連續(剛剛的例子在x=0時，MAE函數就不可以微分)，因此可能在執行時容易出錯，MSE對outlier較敏感，但在求解時，比較容易找到穩定的解。\n",
    "        - also see L1, L2 Regularization\n",
    "- **分類問題**常用的損失函數: **cross-entropy**\n",
    "    - A考試及格的機率是$p(xA)=0.4$，B考試及格的機率是$p(xB)=0.99$。這時候$I(xA)=-log(0.4)= 1.322$，$I(xB)=-log(0.99)= 0.014$\n",
    "        - A的訊息量比B還大，這怎麼解釋哩，A及格的機率很低，如果A忽然及格了，會引起大家的注意，所以相對的訊息量較大，但B因為幾乎都滿分，大家對B及格習以為常，B考及格大家都不是很在意，所以信息量較小。\n",
    "        - 機率越隨機(可能一下成績高一下成績低)的情況，訊息量比較大。\n",
    "        - **Entropy是量測不確定性**: 從此例可以得知B還沒考試我就知道他考試及格機率是0.99，白話說考一百次才不及格一次，幾乎不會猜錯(很確定)，算出來的Entropy很小。但A及格機率是0.4，因為一百次考試她會及格40次，我們也很難猜到她會不會及格，所以很容易猜錯(不確定性大)，算出來的Entropy很大。那什麼時候Entropy最大哩，答案就是p=0.5時候，完全猜不到的情況，Entropy=1\n",
    "        - this may also related to KLD (Kullback-Leibler divergence, based on entropy): a meansure of suprise\n",
    "    - cross-entropy越小，代表模型越好\n",
    "        \n",
    "[好文](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E4%BB%8B%E7%B4%B9-%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-loss-function-2dcac5ebb6cb)\n",
    "\n",
    "- ` logitcrossentropy(ŷ, y; weight = 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate(test)[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test` (type: `DataLoader`) is a generator that outputs (x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_loss()\n",
    "    L = 0f0 # Use Float32 to save GPU memory\n",
    "    for (x, y) in test\n",
    "        L += loss(x, y)\n",
    "    end\n",
    "    L/length(test)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`evalcb()`: evaluate call back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb() = @show(test_loss()) # for displaying current progress only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cb`: an additional argument, used for callbacks so that you can see the training process. \n",
    "`ADAM`: an optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.8612522f0\n",
      "test_loss() = 1.0767492f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.35899606f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.23955083f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.12156515f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.16015524f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.100254f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.1186793f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.105872974f0\n",
      "test_loss() = 0.11349766f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.10412069f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 11\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 12\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.12895682f0\n",
      "test_loss() = 0.12616928f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 13\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.10845351f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 14\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.14078231f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 15\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 16\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.13358337f0\n",
      "test_loss() = 0.14387587f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 17\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 18\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.16247737f0\n",
      "test_loss() = 0.16038367f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 19\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 20\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 0.13691534f0\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "timeout_in_seconds = 10\n",
    "ps = Flux.params(model)\n",
    "@epochs epochs Flux.train!(loss, ps, train, ADAM(0.005), cb=throttle(evalcb, timeout_in_seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型評估\n",
    "- `onecold`: the inverse operation of `onehot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
