{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia 深度學習：卷積神經網路模型簡介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本範例有可選用套件 CuArrays，請在執行以下範例前先安裝。\n",
    "\n",
    "```\n",
    "] add CuArrays\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"CuArrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if error occurred during precompling Flux, close jupyter and re-open as administrator\n",
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy\n",
    "using MLDatasets\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (convolutional neural networks) 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### `Flux.MaxPool`\n",
    "\n",
    "<img src=\"maxpoolExplain.png\" width=400/>\n",
    "\n",
    "- `MaxPool(k; pad = 0, stride = k)`\n",
    "    - Max pooling layer. k is the size of the window for each dimension of the input.\n",
    "    \n",
    "- [Max-pooling](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling)\n",
    "    - a sample-based discretization process\n",
    "    - to down-sample an input representation\n",
    "    - to help over-fitting by providing an abstracted form of the representation\n",
    "    - reduces the computational cost \n",
    "    - `MeanPool` works in a similar way but using a `mean` filter instead of the `max`.\n",
    " \n",
    "#### convolutonal layer\n",
    "\n",
    "<img src=\"ConvExplain.png\" width=400/>\n",
    "\n",
    "- `Conv((3, 3), 1=>16, pad=(1,1), relu)`\n",
    "    - Apply a Conv layer to a **1**-channel input using a **3×3** window size, giving us a **16**-channel output. Output is activated with **ReLU**.\n",
    "    - In this example, the images are in grayscale. One-channel means the input is one 2d-array one time. If the images are colored, there are 3 channels (RGB) for one image, hence the convolutional layer should be `Conv((3, 3), 3=>16, pad=(1,1), relu)` (or `3=>any integer`)\n",
    "\n",
    "- `Conv((3, 3), 16=>32, pad=(1,1), relu)`\n",
    "    - Apply a Conv layer to a **16**-channel input using a **3×3** window size, giving us a **32**-channel output. Output is activated with **ReLU**.\n",
    "\n",
    "\n",
    "Feature map\n",
    "\n",
    "- 一般卷積網路過程中，除了Input image不稱為Feature map外，中間產生的圖我們都稱之為Feature map，原因很簡單就是這些中間產生的圖都是為了「描繪出該任務所應該產生對應的特徵資料」\n",
    "    \n",
    "一個卷積計算基本上有幾個部份:\n",
    "\n",
    "- 輸入的圖: 假設大小是W × W。\n",
    "- Filter (kernel map)大小是 ks × ks\n",
    "- Stride: kernel map在移動時的步伐長度 S\n",
    "- 輸出的圖大小為 new_height × new_width\n",
    "\n",
    "Padding\n",
    "- 卷積後的圖內縮的格數。[更多](https://medium.com/@chih.sheng.huang821/%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-convolutional-neural-network-cnn-%E5%8D%B7%E7%A9%8D%E8%A8%88%E7%AE%97%E4%B8%AD%E7%9A%84%E6%AD%A5%E4%BC%90-stride-%E5%92%8C%E5%A1%AB%E5%85%85-padding-94449e638e82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), flatten, Dense(288, 10), softmax)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)), \n",
    "    flatten,\n",
    "    Dense(288, 10),\n",
    "    softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputsize = (28,28)\n",
    "Flux.outdims(\n",
    "    Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2))), \n",
    "    inputsize\n",
    ") # output (3, 3);\n",
    "# and 3*3*32 = 288 is the input number of nodes for Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28×16×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0501221  0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.107333   0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.131159   0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.126036   0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.109219   0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0604286  0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0447327  0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0        0.0193759  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.000997848     0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.00679975      0.0175514  0.0        0.0  0.0\n",
       " ⋮                                ⋱             ⋮               \n",
       " 0.0  0.0  0.0  0.0  0.0802622       0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.101311        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0628125       0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0709549       0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.131077     …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.159483        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.121825        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0466786       0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.00631192      0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0684451  0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0959011  0.0532365  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0576606  0.0172807  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.000530279     0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.00452544      0.0        0.0        0.0  0.0\n",
       " ⋮                                ⋱             ⋮               \n",
       " 0.0  0.0  0.0  0.0  0.0914442       0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.168618        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.165842        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.14761         0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.13527      …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.259018        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.288448        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.207375        0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0773768       0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0          …  0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0             0.0        0.0        0.0  0.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0         …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0         …  0.0376435  0.0516452   0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.096476   0.0777123   0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.132074   0.0956655   0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.143894   0.10797     0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.116355   0.059936    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0         …  0.135419   0.0920084   0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.148719   0.0377651   0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.121246   0.00356474  0.0  0.0\n",
       " ⋮                        ⋮           ⋱             ⋮                \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0         …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.00371768     0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0         …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0            0.0        0.0         0.0  0.0\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 14, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.102994  0.00889004  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.193522  0.111231    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.310075  0.242478    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.432388  0.285306    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.440988  0.282626    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.406933  0.249045    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.413853  0.180228    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.302981  0.142371    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.311645  0.059459    0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.188126  0.0058568   0.0  0.0\n",
       " ⋮                               ⋱            ⋮                \n",
       " 0.0  0.0  0.0  0.0  0.00879792     0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0212407      0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0       0.0         0.0  0.0\n",
       "\n",
       "[:, :, 15, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0839427   0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0507758   0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.00310547  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.00192057     0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.00954781     0.0         0.0  0.0  0.0  0.0\n",
       " ⋮                               ⋱                   ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0146135      0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0961337      0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.191457       0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0691316   …  0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0872463      0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0677223      0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0607654      0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0742457      0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0         …  0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0            0.0         0.0  0.0  0.0  0.0\n",
       "\n",
       "[:, :, 16, 1] =\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0        …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.100779   0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.177402   0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0        …  0.158227   0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.156948   0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.123911   0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0667331  0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0595413  0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0        …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.00840363  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.00156171  0.0  0.0\n",
       " ⋮                              ⋮          ⋱             ⋮                \n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0        …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0090874     0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0294356  0.0181096     0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0        …  0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0        0.0           0.0        0.0         0.0  0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:,:,:,1:1] |> Conv((3, 3), 1=>16, pad=(1,1), relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data X: type = Array{Float32,3}, size = (28, 28, 60000)\n",
      "Training data y: type = Array{Int64,1}, size = (60000,)\n",
      "Testing data X: type = Array{Float32,3}, size = (28, 28, 10000)\n",
      "Testing data y: type = Array{Int64,1}, size = (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = MNIST.traindata(Float32)\n",
    "test_X, test_y = MNIST.testdata(Float32)\n",
    "println(\"Training data X: type = $(typeof(train_X)), size = $(size(train_X))\")\n",
    "println(\"Training data y: type = $(typeof(train_y)), size = $(size(train_y))\")\n",
    "println(\"Testing data X: type = $(typeof(test_X)), size = $(size(test_X))\")\n",
    "println(\"Testing data y: type = $(typeof(test_y)), size = $(size(test_y))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data X: type = Array{Float32,4}, size = (28, 28, 1, 60000)\n",
      "Testing data X: type = Array{Float32,4}, size = (28, 28, 1, 10000)\n",
      "Training data y: type = Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}, size = (10, 60000)\n",
      "Testing data y: type = Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}, size = (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "train_X = reshape(train_X, 28, 28, 1, :)\n",
    "test_X = reshape(test_X, 28, 28, 1, :)\n",
    "train_y = onehotbatch(train_y, 0:9)\n",
    "test_y = onehotbatch(test_y, 0:9)\n",
    "println(\"Training data X: type = $(typeof(train_X)), size = $(size(train_X))\")\n",
    "println(\"Testing data X: type = $(typeof(test_X)), size = $(size(test_X))\")\n",
    "println(\"Training data y: type = $(typeof(train_y)), size = $(size(train_y))\")\n",
    "println(\"Testing data y: type = $(typeof(test_y)), size = $(size(test_y))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CuArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10000 Flux.OneHotMatrix{CuArray{Flux.OneHotVector,1,Nothing}}:\n",
       " 0  0  0  1  0  0  0  0  0  0  1  0  0  …  0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  1  0  0  1  0  0  0  0  0  0  0     0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  1  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  1  0  1  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  1  0  0\n",
       " 0  0  0  0  0  0  0  0  1  0  0  0  0  …  1  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0     0  1  0  0  0  0  0  0  0  0  0  1\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0     0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  0  1  0  0  1     0  0  0  0  1  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Performing scalar operations on GPU arrays: This is very slow, consider disallowing these operations with `allowscalar(false)`\n",
      "└ @ GPUArrays C:\\Users\\HSI\\.julia\\packages\\GPUArrays\\HGtNV\\src\\host\\indexing.jl:43\n"
     ]
    }
   ],
   "source": [
    "model = model |> gpu\n",
    "train_X = train_X |> gpu\n",
    "train_y = train_y |> gpu\n",
    "test_X = test_X |> gpu\n",
    "test_y = test_y |> gpu\n",
    "# there is a warning, feel free to ignore it (by ZK 2020-05-29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料2\n",
    "- DataLoader必須要在 `XXX |> gpu`之後做，否則會出錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader((Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 1024, 10000, true, 10000, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], false)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 1024\n",
    "train = DataLoader(train_X, train_y, batchsize=batchsize, shuffle=true)\n",
    "test = DataLoader(test_X, test_y, batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_loss()\n",
    "    l = 0f0\n",
    "    for (x, y) in test\n",
    "        l += loss(x, y)\n",
    "    end\n",
    "    l/length(test)\n",
    "end\n",
    "evalcb() = @show(test_loss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZK's setting\n",
    "learining_rate = 0.002;\n",
    "decay = 0.1;\n",
    "decay_step = 1;\n",
    "clip = 1e-4;\n",
    "optimizer = Flux.Optimiser(ExpDecay(learining_rate, decay, decay_step, clip), ADAM(learining_rate));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 2.2973819f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.952109f0\n",
      "test_loss() = 1.6300522f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.5281941f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.5152304f0\n",
      "test_loss() = 1.5124364f0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4915422f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4846131f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.486607f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4765952f0\n",
      "test_loss() = 1.4757137f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 11\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n",
      "┌ Info: Epoch 12\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4790752f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 13\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4733231f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 14\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.474279f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 15\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4745872f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 16\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4761641f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 17\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4746133f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 18\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4749229f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 19\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.472168f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 20\n",
      "└ @ Main C:\\Users\\HSI\\.julia\\packages\\Flux\\Fj3bt\\src\\optimise\\train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.4723116f0\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "@epochs epochs Flux.train!(loss, params(model), train, ADAM(0.005), cb=throttle(evalcb, 10))\n",
    "# @epochs epochs Flux.train!(loss, params(model), train, optimizer, cb=throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
